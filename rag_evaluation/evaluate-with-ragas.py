import os
import faiss
import openai
import numpy as np
from dotenv import load_dotenv

from datasets import Dataset

from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from langchain_ollama.chat_models import ChatOllama
from langchain_community.embeddings import HuggingFaceBgeEmbeddings

from ragas import evaluate
from ragas.metrics import (
    answer_correctness,
    answer_relevancy,
    faithfulness,
    context_precision,
    context_recall,
)


# Load environment variables. Assumes that project contains .env file with API keys
load_dotenv()
"""
Document Corpus:
A small list of factual sentences is used as the knowledge base.
"""

docs = [
    "Paris is the capital and most populous city of France. The city is famed for the Eiffel Tower.",
    "Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.",
    "The Great Wall of China is a series of fortifications built to protect the ancient Chinese states.",
    "Mount Everest, part of the Himalayas, is Earth’s highest mountain above sea level.",
    "Mike loves the color pink more than any other color."
]

"""
OpenAI Client and Embedding Function
 - Initializes the OpenAI client.
 - Defines a function to get text embeddings using OpenAI’s embedding model.
"""
# Initialize OpenAI client
client = openai.OpenAI()
# 
def get_embedding(text):
    response = client.embeddings.create(model="text-embedding-3-small", input=text)
    return response.data[0].embedding

"""
Vector Database:
 - Creates a FAISS index to store and search for relevant documents.
 - Embeds all documents.
 - Creates a FAISS index for fast similarity search.
 - Normalizes embeddings for cosine similarity.
"""
embeddings = np.array([get_embedding(d) for d in docs]).astype('float32')
index = faiss.IndexFlatIP(embeddings.shape[1])
faiss.normalize_L2(embeddings)
index.add(embeddings)

"""
Retrieval Function:
- Embeds the query, normalizes it, and retrieves the top-k most similar documents
 - Takes a query and returns the top k most relevant documents.
"""
def retrieve(query, k):
    query_embedding = np.array([get_embedding(query)]).astype("float32")
    
    faiss.normalize_L2(query_embedding)
    _, idx = index.search(query_embedding, k)
    
    return [docs[i] for i in idx[0]]
    
"""
Answer Generation Function
 - Takes a question and a list of context documents.
 - Formulates a prompt that instructs the LLM to answer the question using only the provided context.
 - Sends the prompt to the OpenAI API and returns the LLM’s response.
 - Calls OpenAI’s GPT-4o to generate an answer, instructing it to use only the provided context.
"""
def generate_answer(question, contexts):
    prompt = (
        "Answer the user question **only** with facts found in the context.\n\n"
        "Context:\n"
        + "\n".join(f"- {c}" for c in contexts)
        + f"\n\nQuestion: {question}\nAnswer:"
    )

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )

    return response.choices[0].message.content.strip()



"""
Evaluation Dataset:
 - Creates a list of questions and ground truth answers.
 - For each question, retrieves the top-k most relevant documents.
 - Generates an answer using the generate_answer function.
 - Creates a row for each question, containing the question, context, answer, and ground truth.
"""

questions = [
    "What is the capital of France?",
    "Who wrote Pride and Prejudice?",
    "Where is Mount Everest located?",
    "What is Mike's favorite color?"
]

ground_truths = [
    "Paris",
    "Jane Austen",
    "the Himalayas",
    "Pink"
]

rows = []

for question, ground_truth in zip(questions, ground_truths):
    context = retrieve(question, k=2)
    answer = generate_answer(question, context)
    rows.append(
        {
            "question": question, # the question asked by the user
            "contexts": context, # the context retrieved from the vector database
            "answer": answer, # the answer generated by the LLMs
            "reference": ground_truth, # the ground truth answer
        }
    )

evaluation_dataset = Dataset.from_list(rows)



"""
Evaluate RAG System with Ragas
- Evaluates the dataset using several RAGAS metrics:
- answer_correctness: Is the answer factually correct?
- answer_relevancy: Is the answer relevant to the question?
- faithfulness: Is the answer faithful to the retrieved context?
- context_precision: How much of the retrieved context is relevant?
- context_recall: How much relevant context was retrieved?
"""

scores = evaluate(
    evaluation_dataset,
    metrics=[
        answer_correctness,
        answer_relevancy,
        faithfulness,
        context_precision,
        context_recall,
    ],
)

"""
Print the results
"""
print(rows)
print(scores)